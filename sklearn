import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.metrics import f1_score
from hyperopt import hp, tpe, fmin, Trials, STATUS_OK


def train_isolation_forest_group(
    df: pd.DataFrame,
    groupby_col: str,
    label_col: str = "true_label",
    max_evals: int = 30
) -> pd.DataFrame:
    """
    Train Isolation Forest per group using F1-score loss and add predictions to df.

    Parameters:
    - df: DataFrame containing numeric features, a groupby column, and a true label column.
    - groupby_col: column name to group by.
    - label_col: name of the true label column (1=anomaly, 0=normal).
    - max_evals: number of hyperopt optimization iterations.

    Returns:
    - DataFrame with added columns: anomaly_label and anomaly_score.
    """
    
    def process_group(group_df):
        # Check if valid ground truth labels exist
        if label_col not in group_df.columns or group_df[label_col].isnull().any():
            group_df["anomaly_label"] = np.nan
            group_df["anomaly_score"] = np.nan
            return group_df

        X = group_df.select_dtypes(include=[np.number]).drop(columns=[label_col], errors='ignore')
        y = group_df[label_col].astype(int)

        if len(X) < 10 or y.nunique() < 2:
            group_df["anomaly_label"] = np.nan
            group_df["anomaly_score"] = np.nan
            return group_df

        space = {
            'n_estimators': hp.choice('n_estimators', range(50, 201)),
            'max_samples': hp.uniform('max_samples', 0.5, 1.0),
            'contamination': hp.uniform('contamination', 0.01, 0.3),
            'max_features': hp.uniform('max_features', 0.5, 1.0)
        }

        def objective(params):
            model = IsolationForest(
                n_estimators=int(params['n_estimators']),
                max_samples=params['max_samples'],
                contamination=params['contamination'],
                max_features=params['max_features'],
                random_state=42,
            )
            try:
                model.fit(X)
                preds = model.predict(X)
                y_pred = (preds == -1).astype(int)  # Convert -1 (anomaly) â†’ 1
                score = f1_score(y, y_pred, zero_division=0)
                return {'loss': -score, 'status': STATUS_OK}
            except:
                return {'loss': float('inf'), 'status': STATUS_OK}

        trials = Trials()
        best_params = fmin(
            fn=objective,
            space=space,
            algo=tpe.suggest,
            max_evals=max_evals,
            trials=trials,
            rstate=np.random.default_rng(42)
        )

        best_model = IsolationForest(
            n_estimators=int(best_params['n_estimators']),
            max_samples=best_params['max_samples'],
            contamination=best_params['contamination'],
            max_features=best_params['max_features'],
            random_state=42,
        )

        best_model.fit(X)
        preds = best_model.predict(X)
        scores = best_model.decision_function(X)

        group_df = group_df.copy()
        group_df.loc[X.index, "anomaly_label"] = preds
        group_df.loc[X.index, "anomaly_score"] = scores

        return group_df

    df_out = df.groupby(groupby_col, group_keys=False).apply(process_group)
    return df_out
